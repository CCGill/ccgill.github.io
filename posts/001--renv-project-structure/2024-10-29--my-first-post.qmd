---
title: Project creation - encouraging reproducibility with renv
description: "Automating renv project creation"
author: "CG"
date: "2024-10-29"
date-modified: "2024-10-29"
categories: [data-science, reproducible, R]
# draft: true
---

# Reproducibility with renv

Since I'm returning to blogging after a number of years, I thought as a first post I'd start with a tool I recently wrote to address something I consider fundamental, but which I frequently find myself advocating for and providing training in - reproducibility in research[^1].  

[^1]: computational reproducibility should not be confused with the so-called reproducibility crisis in research, which spans far beyond only being able to reproduce results from your code and a fixed dataset.  However, computational reproducibility is essential for the credibility of results - if you can't reproduce your computational results from the source data, you should not trust them or publish them.  This has a strong implication for record-keeping, and version control for both code and datasets.


This will be a short post as, more specifically, I'll briefly discuss a [useful script](https://github.com/CCGill/create-renv-analysis-project/blob/main/setup-r-project) I recently developed to setup an R analysis project with renv.  The only requirement is a functioning R installation and jupyter-client.

The key reason for developing this script is to automate:

- creation of a common project folder structure.
- creation of an renv environment ready to use.
- installation of an R jupyter kernel ready for use.

While this is a good start, it's important to note that renv does not cover all aspects of reproducibility - some caveats are noted [in the renv documentation](https://rstudio.github.io/renv/articles/renv.html), but critically if used correctly it does capture package dependency versions and the R version.  Since I now frequently manage cloud compute environments using infrastructure-as-code tools such as terraform, and I can define start-up scripts to install dependencies such as R versions, this script is sufficient for reproducibility.

The script requires a kernel-name and project folder location as arguments and carries out the following steps:

1. Constructs an analysis-ready folder structure.  This is quite opinionated, but it has proven useful:
```default
/path/to/project/directory/
├── data
│   ├── 00_source
│   ├── 01_staging
│   └── 02_final
├── figures
├── notebooks
└── output
    ├── data
    ├── figures
    └── other
```

2. Initialises an renv environment in the project root directory.
3. Installs the IRkernel package and installs the corresponding kernel for the user.
4. Creates an R script to reinstall the kernel for the user in the notebooks folder.
5. Ensures the renv environment is active in the notebooks directory.  This is achieved by creating a particular .Rprofile file.

The final project directory structure is as follows (having removed all of the additional files installed in the renv/ folder):
```default
/path/to/project/directory/
├── data
│   ├── 00_source
│   ├── 01_staging
│   └── 02_final
├── figures
├── notebooks
│   └── 00-install-kernel.R
├── output
│   ├── data
│   ├── figures
│   └── other
├── renv/...
└── renv.lock
```

I have found such a structure useful as it ensures 

- **Ease of use for others**: 
    - Perhaps most importantly it is portable, this project can be handed to another user/colleague and it is relatively easy to understand, assuming your code is well-written and naming conventions are sensible - this may be the subject of another post [^3].
    - Having introduced a similar setup script like this to others, I have found it eases the transition from writing R code to creating reproducible analyses.  This is particularly true for those new to computational analysis or those who are not computational scientists and engineers.
    
[^3]: Regarding naming conventions - personally I name wrapper scripts/notebooks/workflows with zero-padded integers followed by meaningful names to ensure it is clear in which order they are run, and place utility scripts and executables in a `bin/` folder.  I use linters for R code and linters and autoformatters (usually black or ruff) for python.  I prefer to use a coding standard, both for consistency, and to ensure that my focus is on code content.  For R I (and Google) recommend the tidyverse code style.  If you're not familiar with these, it may be worth reading the [tidyverse style guide](https://style.tidyverse.org/) and [Google's additions](https://google.github.io/styleguide/Rguide.html).

- **Ease of use for me**:
    - The existence of the folders is a useful reminder how to keep the output and working files organised.
    - The only rule the user needs to remember is to keep all running code in the notebooks directory and to run renv::snapshot() periodically.
    - This is much faster than `conda`, and after supporting several users using conda, I have found the conda dependency management for R packages to be unreliable at times.

The immediate availability of the jupyter kernel is another key efficiency here, following project setup I can immediately open jupyter notebooks with the relevant R kernel in the notebooks directory.

Note that it can also be extended to python virtual environments or conda managed python by keeping all environment configuration in the root directory (for example requirements.txt/environment.yml files, venv folders).

## Enabling renv in the notebooks folder

This was both the biggest surprise when I started using renv, and the trickiest part to get right in this project structure.  As noted, any R session started in the notebooks folder will use the renv stored in the root directory.  This is enabled by creating a .Rprofile file in the notebooks directory containing the following line (as described in a GitHub issue [here](https://github.com/rstudio/renv/issues/946)):
```default
owd <- setwd(".."); source("renv/activate.R"); setwd(owd)
```
The .Rprofile file is run when an R session is started (see [here](https://rstudio.github.io/renv/) for more details about renv, and good pointers to the flexible but relatively complex configuration options for R).  This file essentially changes the working directory to the root (parent) directory, activates the renv R environment there, and changes directory back to the notebooks directory again.



I hope this script is useful to others - it has proven invaluable for me, and I expect to optimize it and add more features/options in future.  It is publicly available on GitHub [here](https://github.com/CCGill/create-renv-analysis-project).
